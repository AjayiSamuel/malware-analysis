#!/usr/bin/env python
# coding: utf-8

# In[2]:


#Feature Extraction

import pandas as pd
import numpy as np
import pdb
import os
import csv

PATH = "Insert file path here/"
data = pd.read_csv(PATH+'malware-analysis/raw_data/sha256_family.csv')

family_column = data["family"]
sha_column = data["sha256"]

FEATURES_SET = {
    "feature": 1,
    "permission": 2,
    "activity": 3,
    "service_receiver": 3,
    "provider": 3,
    "service": 3,
    "intent": 4,
    "api_call": 5,
    "real_permission": 6,
    "call": 7,
    "url": 8
}

def count_feature_set(lines):
    """
    Count how many features belong to a specific set
    :param lines: features in the text file
    :return:
    """
    features_map = {x: 0 for x in range(1, 9)}
    for l in lines:
        if l != "\n":
            set = l.split("::")[0]
            features_map[FEATURES_SET[set]] += 1
    features = []
    for i in range(1, 9):
        features.append(features_map[i])
    return features

feature_count = []
def read_sha_files():
    for filename in os.listdir(PATH+'malware-analysis/raw_data/feature_vectors'):
        sha_data = open(PATH+'malware-analysis/raw_data/feature_vectors/'+ filename)
        feature_count.append([filename] + count_feature_set(sha_data))
        sha_data.close()
    return feature_count

header = ['sha256', 'feature', 'permission', 'activity', 'intent', 'api_call', 'real_permission', 'call', 'url' ]
def create_csv_for_sha_data():
    with open(PATH+'malware-analysis/processed_data/feature_vectors.csv", "wt", newline ='') as file:
        writer = csv.writer(file, delimiter=',')
        writer.writerow(i for i in header)
        for j in read_sha_files():
            writer.writerow(j)

create_csv_for_sha_data()

feature_vectors_data = pd.read_csv(PATH+'malware-analysis/processed_data/feature_vectors.csv')
sha256_data = feature_vectors_data['sha256']

mask = np.in1d(sha256_data, sha_column)


# feature_vectors_data
output = pd.DataFrame({'output' : mask })
feature_vectors_data = feature_vectors_data.merge(output, left_index = True, right_index = True)
feature_vectors_data.to_csv(PATH+'malware-analysis/feature_vectors_data.csv')


# In[5]:


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression as LG
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import precision_score as precision
from sklearn.metrics import recall_score as recall
from sklearn.metrics import roc_auc_score as auc_score
from sklearn.utils import resample
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix as cm

training_data = pd.read_csv('/home/mokeam/Documents/ML/Homework/malware-analysis/processed_data/feature_vectors_data.csv')

df_majority = training_data[training_data.output == 0]
df_minority = training_data[training_data.output == 1]

# Upsampling minority class
df_minority_upsampled = resample(df_minority,replace=True,n_samples=123453,random_state=123)
df_upsampled = pd.concat([df_majority,df_minority_upsampled])

#Downsampling majority class
df_majority_downsampled = resample(df_majority,replace=False,n_samples=len(df_minority),random_state=123)
df_downsampled = pd.concat([df_majority_downsampled,df_minority])

# Encoding our output value [True =1. False = 0]
label_encoder = LabelEncoder()


# In[6]:


import matplotlib.pyplot as plt; plt.rcdefaults()
import numpy as np
import matplotlib.pyplot as plt

print("Figure 1")

data = pd.read_csv(PATH+'malware-analysis/raw_data/sha256_family.csv')
sha_column = data["sha256"]

feature_vectors_data = pd.read_csv(PATH+'malware-analysis/processed_data/feature_vectors.csv')
sha256_data = feature_vectors_data['sha256']


objects = ('Malware','Malware and not Malware')

y_pos = np.arange(len(objects))
performance = [len(sha_column),len(sha256_data)]

plt.bar(y_pos, performance, align='center', alpha=0.5)
plt.xticks(y_pos, objects)
plt.ylabel('Drebin Dataset')

plt.show()


# In[7]:


# Upsampling minority class
print("Figure 2")
objects = ('Malware','Malware and not Malware')

y_pos = np.arange(len(objects))
performance = [len(df_upsampled[df_upsampled.output ==1]),len(df_upsampled[df_upsampled.output ==0])]

plt.bar(y_pos, performance, align='center', alpha=0.5)
plt.xticks(y_pos, objects)
plt.ylabel('Upsampled Drebin Dataset')

plt.show()


# In[8]:


from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import precision_score as precision
from sklearn.metrics import recall_score as recall
from sklearn.metrics import roc_auc_score as auc_score

# Encoding upsampled dataset
output_integer_encoded  = label_encoder.fit_transform(df_upsampled['output'])

#Upsampling the minority class
#Splitting my data in ratio of 30:70 percent
features_train, features_test, labels_train, labels_test = train_test_split(df_upsampled.iloc[:,2:10], output_integer_encoded, test_size=0.3, random_state=0)

# Train our model with LogisticRegression
clf = LG().fit(features_train, labels_train)

# Model Prediction
LG_predictions_class_test = clf.predict(features_test)

print("Logistic Regression for Upsampled dataset:")
print(" ")
# Compute Model Accuracy
LG_accuracy = acc(labels_test, LG_predictions_class_test)
print('accuracy:', LG_accuracy)

# Compute Model Precision
LG_precision = precision(labels_test, LG_predictions_class_test)
print('precision:', LG_precision)

# Compute Model Recall
LG_recall = recall(labels_test, LG_predictions_class_test)
print('recall:', LG_recall)

# Compute Model ROC AUC Score
LG_auc = auc_score(labels_test, LG_predictions_class_test)
print('auc:', LG_auc)

print(" ")
print("Figure 3")
LG_cm = cm(labels_test,LG_predictions_class_test)

# Show confusion matrix in a separate window
plt.matshow(LG_cm)
plt.title('LG Upsampled Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()


print("----------------------------------------------------")

# Train model with Random Forest Classifier
RFC_clf = RandomForestClassifier()
RFC_clf = RFC_clf.fit(features_train, labels_train)


# Model Prediction
RFC_predictions_class_test = RFC_clf.predict(features_test)

print("Random Forest Classifier for Upsampled dataset:")
print(" ")
# Compute Model Accuracy
RFC_accuracy = acc(labels_test, RFC_predictions_class_test)
print('accuracy: ', RFC_accuracy)

# Compute Model Precision
RFC_precision = precision(labels_test, RFC_predictions_class_test)
print('precision: ', RFC_precision)

# Compute Model Recall
RFC_recall = recall(labels_test, RFC_predictions_class_test)
print('recall: ', RFC_recall)

# Compute Model ROC AUC Score
RFC_auc = auc_score(labels_test, RFC_predictions_class_test)
print('auc: ', RFC_auc)

RFC_cm = cm(labels_test,RFC_predictions_class_test)

print(" ")
print("Figure 4")

# Show confusion matrix in a separate window
plt.matshow(RFC_cm)
plt.title('RFC Upsampled Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()



# In[9]:


# Downsampling majority class
print("Figure 5")
objects = ('Malware','Malware and not Malware')

y_pos = np.arange(len(objects))
performance = [len(df_downsampled[df_downsampled.output ==1]),len(df_downsampled[df_downsampled.output ==0])]

plt.bar(y_pos, performance, align='center', alpha=0.5)
plt.xticks(y_pos, objects)
plt.ylabel('Downsampled Drebin Dataset')

plt.show()


# In[10]:


from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import precision_score as precision
from sklearn.metrics import recall_score as recall
from sklearn.metrics import roc_auc_score as auc_score

# Encoding downsampled dataset
output_integer_encoded  = label_encoder.fit_transform(df_downsampled['output'])

# Downsampling the majority class
# Splitting my data in ratio of 30:70 percent
features_train, features_test, labels_train, labels_test = train_test_split(df_downsampled.iloc[:,2:10], output_integer_encoded, test_size=0.3, random_state=0)

# Train our model with LogisticRegression
clf = LG().fit(features_train, labels_train)

# Model Prediction
LG_predictions_class_test = clf.predict(features_test)

print("Logistic Regression for Downsampled dataset:")
print(" ")
# Compute Model Accuracy
LG_accuracy = acc(labels_test, LG_predictions_class_test)
print('accuracy:', LG_accuracy)

# Compute Model Precision
LG_precision = precision(labels_test, LG_predictions_class_test)
print('precision:', LG_precision)

# Compute Model Recall
LG_recall = recall(labels_test, LG_predictions_class_test)
print('recall:', LG_recall)

# Compute Model ROC AUC Score
LG_auc = auc_score(labels_test, LG_predictions_class_test)
print('auc:', LG_auc)

LG_cm = cm(labels_test,LG_predictions_class_test)

print(" ")
print("Figure 6")

# Show confusion matrix in a separate window
plt.matshow(LG_cm)
plt.title('LG Downsampled Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()


print("----------------------------------------------------")

# Train model with Random Forest Classifier
RFC_clf = RandomForestClassifier()
RFC_clf = RFC_clf.fit(features_train, labels_train)


# Model Prediction
RFC_predictions_class_test = RFC_clf.predict(features_test)

print("Random Forest Classifier for Downsampled dataset:")
print(" ")
# Compute Model Accuracy
RFC_accuracy = acc(labels_test, RFC_predictions_class_test)
print('accuracy:', RFC_accuracy)

# Compute Model Precision
RFC_precision = precision(labels_test, RFC_predictions_class_test)
print('precision:', RFC_precision)

# Compute Model Recall
RFC_recall = recall(labels_test, RFC_predictions_class_test)
print('recall:', RFC_recall)

# Compute Model ROC AUC Score
RFC_auc = auc_score(labels_test, RFC_predictions_class_test)
print('auc:', RFC_auc)

RFC_cm = cm(labels_test,RFC_predictions_class_test)

print(" ")
print("Figure 7")

# Show confusion matrix in a separate window
plt.matshow(RFC_cm)
plt.title('RFC Downsampled Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

